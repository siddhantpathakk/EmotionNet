{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import AudioEmbeddingNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = './tmp/examples/utt0.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/siddhantpathak/.cache/torch/hub/harritaylor_torchvggish_master\n"
     ]
    }
   ],
   "source": [
    "model = AudioEmbeddingNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[154.5000,   8.0000, 197.0000, 132.5000, 215.0000,  91.0000, 128.0000,\n",
       "          83.0000, 129.5000, 222.5000,  83.5000,  18.5000, 123.5000, 163.5000,\n",
       "          96.5000,  54.5000, 157.0000, 169.5000, 166.5000, 146.0000,  87.5000,\n",
       "         238.0000, 134.5000, 138.0000,   0.0000, 225.0000,  73.5000,  70.0000,\n",
       "          66.5000, 109.5000, 123.0000,  87.5000, 161.0000, 135.5000, 138.0000,\n",
       "         126.5000, 111.0000,  39.0000,  91.0000,  96.0000, 141.0000, 126.5000,\n",
       "           0.0000, 187.0000, 125.5000,  90.5000, 125.0000, 145.0000,  29.5000,\n",
       "         141.0000, 198.0000, 114.0000, 108.5000, 123.0000, 130.0000,  97.0000,\n",
       "          53.5000,  60.5000, 195.0000, 243.5000, 109.5000,   0.5000,  10.5000,\n",
       "         182.0000, 223.5000, 127.5000, 236.5000, 209.5000, 162.0000, 138.5000,\n",
       "         102.5000,  78.5000, 161.5000, 199.0000, 115.5000,  63.5000,  91.5000,\n",
       "         255.0000,  55.5000, 255.0000,  87.0000,  80.5000, 157.0000, 230.5000,\n",
       "         206.5000, 123.0000, 161.5000, 194.5000, 255.0000, 117.0000, 199.0000,\n",
       "         144.0000, 194.5000, 255.0000, 140.0000, 182.5000,  57.0000,  30.0000,\n",
       "          39.0000,   0.0000,  72.5000,  76.0000, 158.0000, 124.0000, 190.5000,\n",
       "         195.5000, 175.5000, 225.0000,  93.0000,  26.0000, 208.5000, 197.0000,\n",
       "         201.0000,   0.0000, 150.5000,  69.5000, 189.0000, 224.0000, 129.0000,\n",
       "         188.5000,  72.5000, 213.0000, 132.0000,  87.0000, 130.5000,   0.0000,\n",
       "         211.5000, 255.0000, 158.0000,  11.0000, 208.0000, 141.0000, 224.0000,\n",
       "          96.0000, 160.0000,  91.0000, 132.0000, 230.0000, 124.0000,  29.0000,\n",
       "         144.0000, 203.0000, 110.0000,  60.0000, 172.0000, 180.0000, 179.0000,\n",
       "         154.0000, 104.0000, 248.0000, 137.0000, 182.0000,   0.0000, 231.0000,\n",
       "         105.0000,  78.0000,  86.0000, 156.0000, 140.0000,  98.0000, 161.0000,\n",
       "         147.0000, 171.0000, 133.0000, 118.0000,  50.0000, 142.0000, 140.0000,\n",
       "         148.0000, 149.0000,   0.0000, 201.0000, 170.0000,  91.0000, 150.0000,\n",
       "         147.0000,  59.0000, 152.0000, 209.0000, 121.0000, 139.0000, 145.0000,\n",
       "         132.0000, 120.0000, 107.0000, 121.0000, 217.0000, 251.0000, 120.0000,\n",
       "           1.0000,  21.0000, 191.0000, 248.0000, 154.0000, 255.0000, 252.0000,\n",
       "         169.0000, 188.0000, 154.0000,  83.0000, 202.0000, 210.0000, 136.0000,\n",
       "         100.0000, 103.0000, 255.0000, 103.0000, 255.0000, 120.0000,  96.0000,\n",
       "         174.0000, 252.0000, 207.0000, 137.0000, 164.0000, 218.0000, 255.0000,\n",
       "         126.0000, 231.0000, 179.0000, 241.0000, 255.0000, 191.0000, 255.0000,\n",
       "          99.0000,  39.0000,  78.0000,   0.0000,  77.0000, 141.0000, 208.0000,\n",
       "         192.0000, 244.0000, 255.0000, 200.0000, 230.0000, 107.0000,  52.0000,\n",
       "         255.0000, 255.0000, 221.0000,   0.0000, 187.0000, 124.0000, 246.0000,\n",
       "         244.0000, 207.0000, 234.0000, 135.0000, 255.0000, 153.0000,  94.0000,\n",
       "         228.0000,   0.0000, 255.0000, 255.0000, 151.0000,   5.0000, 186.0000,\n",
       "         124.0000, 206.0000,  86.0000,  96.0000,  75.0000, 127.0000, 215.0000,\n",
       "          43.0000,   8.0000, 103.0000, 124.0000,  83.0000,  49.0000, 142.0000,\n",
       "         159.0000, 154.0000, 138.0000,  71.0000, 228.0000, 132.0000,  94.0000,\n",
       "           0.0000, 219.0000,  42.0000,  62.0000,  47.0000,  63.0000, 106.0000,\n",
       "          77.0000, 161.0000, 124.0000, 105.0000, 120.0000, 104.0000,  28.0000,\n",
       "          40.0000,  52.0000, 134.0000, 104.0000,   0.0000, 173.0000,  81.0000,\n",
       "          90.0000, 100.0000, 143.0000,   0.0000, 130.0000, 187.0000, 107.0000,\n",
       "          78.0000, 101.0000, 128.0000,  74.0000,   0.0000,   0.0000, 173.0000,\n",
       "         236.0000,  99.0000,   0.0000,   0.0000, 173.0000, 199.0000, 101.0000,\n",
       "         218.0000, 167.0000, 155.0000,  89.0000,  51.0000,  74.0000, 121.0000,\n",
       "         188.0000,  95.0000,  27.0000,  80.0000, 255.0000,   8.0000, 255.0000,\n",
       "          54.0000,  65.0000, 140.0000, 209.0000, 206.0000, 109.0000, 159.0000,\n",
       "         171.0000, 255.0000, 108.0000, 167.0000, 109.0000, 148.0000, 255.0000,\n",
       "          89.0000, 110.0000,  15.0000,  21.0000,   0.0000,   0.0000,  68.0000,\n",
       "          11.0000, 108.0000,  56.0000, 137.0000, 136.0000, 151.0000, 220.0000,\n",
       "          79.0000,   0.0000, 162.0000, 139.0000, 181.0000,   0.0000, 114.0000,\n",
       "          15.0000, 132.0000, 204.0000,  51.0000, 143.0000,  10.0000, 171.0000,\n",
       "         111.0000,  80.0000,  33.0000,   0.0000, 168.0000, 255.0000]],\n",
       "       grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class NNCell(nn.Module):\n",
    "    def __init__(self, D_u, D_c, D_s, D_i, D_e, D_a):\n",
    "        \"\"\"\n",
    "        D_u: Input dimension u\n",
    "        D_c: CumulativeContext dimension\n",
    "        D_s: SelfSpeaker dimension\n",
    "        D_i: IntraSpeaker dimension\n",
    "        D_e: EmotionState dimension\n",
    "        D_a: Attention vector dimension\n",
    "        \"\"\"\n",
    "        super(NNCell, self).__init__()\n",
    "\n",
    "        # Defining the GRU cells for different states\n",
    "        self.GRU_c  = nn.GRUCell(D_c + D_s + D_i + D_u, D_c)\n",
    "        self.GRU_sk = nn.GRUCell(D_c + D_u, D_s)\n",
    "        self.GRU_i  = nn.GRUCell(D_a + D_u, D_i)\n",
    "        self.GRU_e  = nn.GRUCell(D_c + D_s + D_u, D_e)\n",
    "        \n",
    "    def forward(self, u, a, C_prev, S_prev, I_prev, E_prev):\n",
    "        \"\"\"\n",
    "        u: Current input\n",
    "        a: Attention vector\n",
    "        C_prev: Previous CumulativeContext\n",
    "        S_prev: Previous SelfSpeaker\n",
    "        I_prev: Previous IntraSpeaker\n",
    "        E_prev: Previous EmotionState\n",
    "        \"\"\"\n",
    "        \n",
    "        # Updating CumulativeContext (C)\n",
    "        C_input = torch.cat([C_prev, S_prev, I_prev, u], dim=1)\n",
    "        C_t = self.GRU_c(C_input, C_prev)\n",
    "        \n",
    "        # Updating SelfSpeaker (S)\n",
    "        S_input = torch.cat([C_t, u], dim=1)\n",
    "        S_t = self.GRU_sk(S_input, S_prev)\n",
    "        \n",
    "        # Updating IntraSpeaker (I)\n",
    "        I_input = torch.cat([a, u], dim=1)\n",
    "        I_t = self.GRU_i(I_input, I_prev)\n",
    "        \n",
    "        # Updating EmotionState (E)\n",
    "        E_input = torch.cat([C_t, S_t, u], dim=1)\n",
    "        E_t = self.GRU_e(E_input, E_prev)\n",
    "\n",
    "        return C_t, S_t, I_t, E_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = NNCell(D_u = 128, D_c = 128, D_s = 128, D_i = 128, D_e = 128, D_a = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NNCell.forward() missing 5 required positional arguments: 'a', 'C_prev', 'S_prev', 'I_prev', and 'E_prev'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/siddhantpathak/Desktop/Projects/neural_networks/audio/test.ipynb Cell 9\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/siddhantpathak/Desktop/Projects/neural_networks/audio/test.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cell(out)\n",
      "File \u001b[0;32m~/anaconda3/envs/nndl_project/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: NNCell.forward() missing 5 required positional arguments: 'a', 'C_prev', 'S_prev', 'I_prev', and 'E_prev'"
     ]
    }
   ],
   "source": [
    "cell(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nndl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
