{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from src.inference.utils import *\n",
    "from src.trainer import load_model_from_ckpt, run_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_path = 'audio/MELD_features/MELD_features_raw.pkl'\n",
    "videoIDs, videoSpeakers, videoLabels, videoText, videoAudio, videoSentence, trainVid, testVid, labels = pd.read_pickle(pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversation(idx, pred_emotions=None):\n",
    "    num_to_label_map = {0: 'neutral', 1: 'surprise', 2: 'fear', 3: 'sadness', 4: 'joy', 5: 'disgust', 6: 'anger'}\n",
    "\n",
    "    list_of_speakers = set(''.join(str(e) for e in speaker) for speaker in videoSpeakers[idx])\n",
    "    num_of_speakers = len(list_of_speakers)\n",
    "    nums = [i+1 for i in range(num_of_speakers)]\n",
    "    speaker_dict = dict(zip(list_of_speakers, nums))\n",
    "\n",
    "    print(f\"Loading dialogue #{idx} with {num_of_speakers} speakers, {len(videoSentence[idx])} utterances.\\n\")\n",
    "\n",
    "    i=1\n",
    "    sentence_count=0\n",
    "    for sentence, speaker, label in zip(videoSentence[idx], videoSpeakers[idx], videoLabels[idx]):\n",
    "        speaker = ''.join(str(e) for e in speaker)\n",
    "        \n",
    "        if pred_emotions is not None:\n",
    "            print(f'[#{i}] Person {speaker_dict[speaker]} ({num_to_label_map[label]} - {num_to_label_map[pred_emotions[sentence_count]]})\\t:\\t{sentence}')\n",
    "        else:\n",
    "            print(f'[#{i}] Person {speaker_dict[speaker]} ({num_to_label_map[label]}) :\\t{sentence}')\n",
    "\n",
    "        i+=1\n",
    "        sentence_count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dialogue #1 with 2 speakers, 7 utterances.\n",
      "\n",
      "[#1] Person 1 (surprise) :\tBut then who? The waitress I went out with last month?\n",
      "[#2] Person 2 (sadness) :\tYou know? Forget it!\n",
      "[#3] Person 1 (surprise) :\tNo-no-no-no, no! Who, who were you talking about?\n",
      "[#4] Person 2 (fear) :\tNo, I-I-I-I don't, I actually don't know\n",
      "[#5] Person 1 (neutral) :\tOk!\n",
      "[#6] Person 1 (neutral) :\tAll right, well...\n",
      "[#7] Person 2 (neutral) :\tYeah, sure!\n"
     ]
    }
   ],
   "source": [
    "# label_map = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger':6}\n",
    "random_idx = random.randint(0, len(videoSentence))\n",
    "load_conversation(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_dir = 'example'\n",
    "speakers_for_utterance = [1,2,2,2,1,1,2]\n",
    "acouf, qmask, umask = get_features_for_dialogue(dialogue_dir=dialogue_dir, X=speakers_for_utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_from_ckpt('audio/MELD_features/models/EmoNet_38.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmotionNet(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (emo_rnn_b): EmotionRNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cell): EmotionGRUCell(\n",
       "      (g_cell): GRUCell(600, 150)\n",
       "      (p_cell): GRUCell(450, 150)\n",
       "      (pl_cell): GRUCell(450, 150)\n",
       "      (r_cell): GRUCell(450, 150)\n",
       "      (rl_cell): GRUCell(450, 150)\n",
       "      (e_cell): GRUCell(600, 150)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (attention): SimpleAttention(\n",
       "        (scalar): Linear(in_features=150, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (emo_rnn_f): EmotionRNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cell): EmotionGRUCell(\n",
       "      (g_cell): GRUCell(600, 150)\n",
       "      (p_cell): GRUCell(450, 150)\n",
       "      (pl_cell): GRUCell(450, 150)\n",
       "      (r_cell): GRUCell(450, 150)\n",
       "      (rl_cell): GRUCell(450, 150)\n",
       "      (e_cell): GRUCell(600, 150)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (attention): SimpleAttention(\n",
       "        (scalar): Linear(in_features=150, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (smax_fc): Linear(in_features=100, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = run_inference(model, acouf.unsqueeze(1), qmask.unsqueeze(1), umask.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dialogue #1 with 2 speakers, 7 utterances.\n",
      "\n",
      "[#1] Person 1 (surprise - neutral)\t:\tBut then who? The waitress I went out with last month?\n",
      "[#2] Person 2 (sadness - neutral)\t:\tYou know? Forget it!\n",
      "[#3] Person 1 (surprise - anger)\t:\tNo-no-no-no, no! Who, who were you talking about?\n",
      "[#4] Person 2 (fear - sadness)\t:\tNo, I-I-I-I don't, I actually don't know\n",
      "[#5] Person 1 (neutral - neutral)\t:\tOk!\n",
      "[#6] Person 1 (neutral - joy)\t:\tAll right, well...\n",
      "[#7] Person 2 (neutral - joy)\t:\tYeah, sure!\n"
     ]
    }
   ],
   "source": [
    "load_conversation(1, preds)\n",
    "# actual_emotion - predicted_emotion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nndl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
