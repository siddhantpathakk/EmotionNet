{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce GTX 1650 Ti (UUID: GPU-55b82302-073f-d276-910b-5e32debb81b0)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "import warnings\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom local imports\n",
    "from src.dataloader import get_MELD_loaders\n",
    "from src.parse import parse_opt\n",
    "from src.trainer import build_model, trainer\n",
    "from src.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ignore the warnings from sklearn.metrics.classification_report\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the arguments and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args: {'batch_size': 2,\n",
      " 'class_weight': False,\n",
      " 'dir': './MELD_features/',\n",
      " 'dropout': 0.2,\n",
      " 'epochs': 100,\n",
      " 'l2': 0.0003,\n",
      " 'loss_fn': 'masked_nll',\n",
      " 'lr': 0.0001,\n",
      " 'mu': 0,\n",
      " 'n_classes': 7,\n",
      " 'no_cuda': False,\n",
      " 'num_workers': 0,\n",
      " 'seed': 100,\n",
      " 'val_split': 0.25,\n",
      " 'verbose': True}\n"
     ]
    }
   ],
   "source": [
    "args = parse_opt()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmotionNet(\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (emo_rnn_b): EmotionRNN(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (cell): EmotionGRUCell(\n",
      "      (g_cell): GRUCell(600, 150)\n",
      "      (p_cell): GRUCell(450, 150)\n",
      "      (pl_cell): GRUCell(450, 150)\n",
      "      (r_cell): GRUCell(450, 150)\n",
      "      (rl_cell): GRUCell(450, 150)\n",
      "      (e_cell): GRUCell(600, 150)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (attention): SimpleAttention(\n",
      "        (scalar): Linear(in_features=150, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (emo_rnn_f): EmotionRNN(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (cell): EmotionGRUCell(\n",
      "      (g_cell): GRUCell(600, 150)\n",
      "      (p_cell): GRUCell(450, 150)\n",
      "      (pl_cell): GRUCell(450, 150)\n",
      "      (r_cell): GRUCell(450, 150)\n",
      "      (rl_cell): GRUCell(450, 150)\n",
      "      (e_cell): GRUCell(600, 150)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (attention): SimpleAttention(\n",
      "        (scalar): Linear(in_features=150, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (smax_fc): Linear(in_features=100, out_features=7, bias=True)\n",
      ")\n",
      "Loss function:\tMaskedNLLLoss\n",
      "Optimizer:\tAdam with initial lr = 0.0001, l2 = 0.0003\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, loss_function = build_model(D_m, D_q, D_g, D_r, D_e, D_h, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = get_MELD_loaders(path = args.dir + 'MELD_features_raw.pkl',\n",
    "                                                           n_classes=args.n_classes,\n",
    "                                                           valid=args.val_split,\n",
    "                                                           batch_size=args.batch_size,\n",
    "                                                           num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1]/[100]\t Train Loss: 1.662\t Train Acc: 41.960%\t Train F1: 35.470\t Val Loss: 1.615\t Val Acc: 47.710%\t Val F1: 31.670\t Test Loss: 1.606\t Test Acc: 49.120%\t Test F1: 34.320\t Time: 118.50 sec\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 3.44 GiB already allocated; 0 bytes free; 3.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\siddh\\Desktop\\Projects\\neural_networks\\audio\\train.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/siddh/Desktop/Projects/neural_networks/audio/train.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model, metrics, best_label, best_pred, best_mask, best_attn, test_class_report \u001b[39m=\u001b[39m trainer(args, model, train_loader, valid_loader, test_loader, optimizer, loss_function)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\Desktop\\Projects\\neural_networks\\audio\\src\\trainer.py:155\u001b[0m, in \u001b[0;36mtrainer\u001b[1;34m(args, model, train_loader, valid_loader, test_loader, optimizer, loss_function)\u001b[0m\n\u001b[0;32m    153\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    154\u001b[0m train_loss, train_acc, _,_,_,train_fscore,_,_\u001b[39m=\u001b[39m train_or_eval_model(model\u001b[39m=\u001b[39mmodel, loss_function\u001b[39m=\u001b[39mloss_function,dataloader\u001b[39m=\u001b[39mtrain_loader, epoch\u001b[39m=\u001b[39me, optimizer\u001b[39m=\u001b[39moptimizer, train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, cuda\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mcuda)\n\u001b[1;32m--> 155\u001b[0m valid_loss, valid_acc, _,_,_,val_fscore,_, _\u001b[39m=\u001b[39m train_or_eval_model(model\u001b[39m=\u001b[39;49mmodel, loss_function\u001b[39m=\u001b[39;49mloss_function, dataloader\u001b[39m=\u001b[39;49mvalid_loader, epoch\u001b[39m=\u001b[39;49me,cuda\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mcuda)\n\u001b[0;32m    156\u001b[0m test_loss, test_acc, test_label, test_pred, test_mask, test_fscore, attentions, test_class_report \u001b[39m=\u001b[39m train_or_eval_model(model\u001b[39m=\u001b[39mmodel, loss_function\u001b[39m=\u001b[39mloss_function, dataloader\u001b[39m=\u001b[39mtest_loader, epoch\u001b[39m=\u001b[39me, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, cuda\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mcuda)\n\u001b[0;32m    159\u001b[0m train_losses\u001b[39m.\u001b[39mappend(train_loss)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\Desktop\\Projects\\neural_networks\\audio\\src\\trainer.py:48\u001b[0m, in \u001b[0;36mtrain_or_eval_model\u001b[1;34m(model, loss_function, dataloader, epoch, optimizer, train, cuda)\u001b[0m\n\u001b[0;32m     44\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     46\u001b[0m textf, acouf, qmask, umask, label \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]] \u001b[39mif\u001b[39;00m cuda \u001b[39melse\u001b[39;00m data[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 48\u001b[0m log_prob, alpha_f, alpha_b \u001b[39m=\u001b[39m model(acouf, qmask,umask) \u001b[39m# seq_len, batch, n_classes\u001b[39;00m\n\u001b[0;32m     50\u001b[0m lp_ \u001b[39m=\u001b[39m log_prob\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,log_prob\u001b[39m.\u001b[39msize()[\u001b[39m2\u001b[39m]) \u001b[39m# batch*seq_len, n_classes\u001b[39;00m\n\u001b[0;32m     51\u001b[0m labels_ \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# batch*seq_len\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siddh\\anaconda3\\envs\\pytorch_ser\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\siddh\\Desktop\\Projects\\neural_networks\\audio\\src\\model.py:215\u001b[0m, in \u001b[0;36mEmotionNet.forward\u001b[1;34m(self, U, qmask, umask)\u001b[0m\n\u001b[0;32m    212\u001b[0m rev_U \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reverse_sequence(U, umask)\n\u001b[0;32m    213\u001b[0m rev_qmask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reverse_sequence(qmask, umask)\n\u001b[1;32m--> 215\u001b[0m emotions_b, alpha_b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49memo_rnn_b(rev_U, rev_qmask)\n\u001b[0;32m    216\u001b[0m emotions_b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reverse_sequence(emotions_b, umask)\n\u001b[0;32m    218\u001b[0m \u001b[39m# print(f'Emotions forward shape: {emotions_f.shape}')\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[39m# print(f'Emotions backward shape: {emotions_b.shape}')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siddh\\anaconda3\\envs\\pytorch_ser\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\siddh\\Desktop\\Projects\\neural_networks\\audio\\src\\model.py:158\u001b[0m, in \u001b[0;36mEmotionRNN.forward\u001b[1;34m(self, U, qmask)\u001b[0m\n\u001b[0;32m    155\u001b[0m alpha \u001b[39m=\u001b[39m []\n\u001b[0;32m    157\u001b[0m \u001b[39mfor\u001b[39;00m u_, qmask_ \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(U, qmask):\n\u001b[1;32m--> 158\u001b[0m     g_, q_, r_, e_, alpha_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcell(u_, qmask_, g_hist, q_, r_, e_)\n\u001b[0;32m    159\u001b[0m     g_hist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([g_hist, g_\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    160\u001b[0m     e \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([e, e_\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\anaconda3\\envs\\pytorch_ser\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\siddh\\Desktop\\Projects\\neural_networks\\audio\\src\\model.py:101\u001b[0m, in \u001b[0;36mEmotionGRUCell.forward\u001b[1;34m(self, U, qmask, g_hist, q0, r0, e0)\u001b[0m\n\u001b[0;32m     99\u001b[0m U_ \u001b[39m=\u001b[39m U\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mexpand(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,qmask\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m],\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD_m)\n\u001b[0;32m    100\u001b[0m rss_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_parties(rs_, qm_idx)\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mexpand(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,qmask\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m],\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD_r)\n\u001b[1;32m--> 101\u001b[0m inp_rl \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([rss_, U_], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    102\u001b[0m rl_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrl_cell(inp_rl, r0\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD_r))\u001b[39m.\u001b[39mview(U\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD_r)\n\u001b[0;32m    103\u001b[0m rl_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(rl_)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 3.44 GiB already allocated; 0 bytes free; 3.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model, metrics, best_label, best_pred, best_mask, best_attn, test_class_report = trainer(args, model, train_loader, valid_loader, test_loader, optimizer, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\siddh\\Desktop\\Projects\\neural_networks\\audio\\train.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/siddh/Desktop/Projects/neural_networks/audio/train.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_losses \u001b[39m=\u001b[39m metrics[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtrain_losses\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/Desktop/Projects/neural_networks/audio/train.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_fscores \u001b[39m=\u001b[39m metrics[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtrain_fscores\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/Desktop/Projects/neural_networks/audio/train.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_accs \u001b[39m=\u001b[39m metrics[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtrain_accs\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "train_losses = metrics['train']['train_losses']\n",
    "train_fscores = metrics['train']['train_fscores']\n",
    "train_accs = metrics['train']['train_accs']\n",
    "\n",
    "val_losses = metrics['val']['val_losses']\n",
    "val_fscores = metrics['val']['val_fscores']\n",
    "val_accs = metrics['val']['val_accs']\n",
    "\n",
    "test_losses = metrics['test']['test_losses']\n",
    "test_fscores = metrics['test']['test_fscores']\n",
    "test_accs = metrics['test']['test_accs']\n",
    "\n",
    "best_fscore = metrics['best']['best_fscore']\n",
    "best_loss = metrics['best']['best_loss']\n",
    "best_acc = metrics['best']['best_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[Metrics]\\t', end='')\n",
    "print('Fscore: {:.3f}\\tLoss: {:.3f}\\tAccuracy: {:.3f}%\\n'.format(best_fscore, best_loss, accuracy_score(best_label,best_pred,sample_weight=best_mask)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nClassification report:')\n",
    "print(classification_report(best_label,best_pred,sample_weight=best_mask,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nConfusion matrix:')\n",
    "print(confusion_matrix(best_label,best_pred,sample_weight=best_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'models/EmoNet_'+str(int(round(best_fscore,0)))+'.pt'\n",
    "torch.save(model.state_dict(), args.dir + model_name)\n",
    "print('\\nModel saved to {}.'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all training metrics per epoch in a dataframe\n",
    "train_metrics = pd.DataFrame(metrics['train'])\n",
    "test_metrics = pd.DataFrame(metrics['test'])\n",
    "val_metrics = pd.DataFrame(metrics['val'])\n",
    "metrics = pd.concat([train_metrics, val_metrics, test_metrics], axis=1)\n",
    "metrics.to_csv(args.dir + 'logs/metrics.csv', index=False)\n",
    "print('Metrics saved to {}.'.format(args.dir + 'logs/metrics.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nndl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
