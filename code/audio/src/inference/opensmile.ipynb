{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenSMILE (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opensmile\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opensmile_feature(audio_file_path, feature_type):\n",
    "    if feature_type == \"emobase\":\n",
    "        smile = opensmile.Smile(\n",
    "            feature_set=opensmile.FeatureSet.emobase,\n",
    "            feature_level=opensmile.FeatureLevel.Functionals,\n",
    "        )\n",
    "    elif feature_type == \"ComParE\":\n",
    "        smile = opensmile.Smile(\n",
    "            feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "            feature_level=opensmile.FeatureLevel.Functionals,\n",
    "        )\n",
    "    else:\n",
    "        smile = opensmile.Smile(\n",
    "            feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "            feature_level=opensmile.FeatureLevel.Functionals,\n",
    "        )\n",
    "    return np.array(smile.process_file(audio_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suggested in https://aclanthology.org/N18-1193.pdf, we use openSMILE with the ComParE configuration to get 6373 features for each utterance video. Z- standardization is performed for voice normaliza- tion and dimension of the audio vector is reduced to 100 using a fully-connected neural layer. This provides the final audio feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "assert_allclose(actual=output_tensor, desired=videoAudio[1][0], atol=2, err_msg='The output tensor is different.', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that our audio features are nearly same to the ones provided as part of open-source code. The difference in exact values arises due to the use of a fully connected layer to reduce the dimension of the audio vector to 300, since each initialisation of weights and biases is done randomly, thus unable to ensure reproducibility."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
